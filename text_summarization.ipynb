{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6b6fa0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in c:\\programdata\\miniconda3\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: torchvision in c:\\programdata\\miniconda3\\lib\\site-packages (0.15.1)\n",
      "Requirement already satisfied: torchaudio in c:\\programdata\\miniconda3\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\miniconda3\\lib\\site-packages (from torch) (3.0)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\miniconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\programdata\\miniconda3\\lib\\site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\miniconda3\\lib\\site-packages (from torch) (3.10.0)\n",
      "Requirement already satisfied: sympy in c:\\programdata\\miniconda3\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\programdata\\miniconda3\\lib\\site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: requests in c:\\programdata\\miniconda3\\lib\\site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\miniconda3\\lib\\site-packages (from torchvision) (1.24.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\miniconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\miniconda3\\lib\\site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\miniconda3\\lib\\site-packages (from requests->torchvision) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\miniconda3\\lib\\site-packages (from requests->torchvision) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\miniconda3\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\programdata\\miniconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2293710d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in c:\\programdata\\miniconda3\\lib\\site-packages (4.27.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\programdata\\miniconda3\\lib\\site-packages (from transformers) (1.24.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\miniconda3\\lib\\site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\miniconda3\\lib\\site-packages (from transformers) (3.10.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\miniconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: requests in c:\\programdata\\miniconda3\\lib\\site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\programdata\\miniconda3\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in c:\\programdata\\miniconda3\\lib\\site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\programdata\\miniconda3\\lib\\site-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\programdata\\miniconda3\\lib\\site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\programdata\\miniconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\miniconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\miniconda3\\lib\\site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\miniconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\miniconda3\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\miniconda3\\lib\\site-packages (from requests->transformers) (1.26.14)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "370fc495",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
    "import PyPDF2\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e3ca157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer \n",
    "tokenizer = PegasusTokenizer.from_pretrained(\"google/pegasus-xsum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f24414ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model \n",
    "model = PegasusForConditionalGeneration.from_pretrained(\"google/pegasus-xsum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a5cd5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(path) :\n",
    "    \n",
    "    pdf_file = open(path, 'rb')\n",
    "    pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "\n",
    "    # Extract text from all pages of the PDF file\n",
    "    l=[]\n",
    "    for page in range(len(pdf_reader.pages)):\n",
    "        l.append(pdf_reader.pages[page].extract_text())\n",
    "    # Close the PDF file\n",
    "    pdf_file.close()\n",
    "\n",
    "    # Print the cleaned text\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de98c71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text) :\n",
    "    # Remove line breaks and other unwanted characters\n",
    "    text = re.sub('\\n', ' ', text)\n",
    "    text = re.sub('[^0-9a-zA-Z\\s]+', '', text)\n",
    "\n",
    "    # Convert all text to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    # Remove extra whitespaces\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    return text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55759ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_text = read_file('C:/Users/MSI/Nouveau dossier/2201.03545v2.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d7f54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\transformers\\generation\\utils.py:1288: UserWarning: Using `max_length`'s default (64) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\transformers\\generation\\utils.py:1288: UserWarning: Using `max_length`'s default (64) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "summary_text=\"\"\n",
    "for page in list_text :\n",
    "    cleaned_text = clean_text(page)  \n",
    "    # Create tokens - number representation of our text\n",
    "    tokens = tokenizer(cleaned_text, truncation=True, padding=\"longest\", return_tensors=\"pt\")\n",
    "    summary = model.generate(**tokens)\n",
    "    summary_text += clean_text(tokenizer.decode(summary[0]).replace(\"<pad>\",\"\")).capitalize() + \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "28dc1e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A family of pure convnet modules convnexts compete with standard convnet modules in terms of accuracy and scalability achieving 878 imagenet top1 transformers on coco detection and ade20k segmentation while maintaining the simplicity and efciency of standard convnetscodes.The evolution of convnets as a computer vision backbone began with the introduction of image classication tasks in the late 1990s and continued with the introduction of hierarchical transformers in the early 2000ss.Figure 1 we introduce a resnet50 model we train it with similar training techniques used to train vision transformers and obtain much improved results compared to the original resnet50 we then study a series of design decisions we summarized as 1 macro design 2 resnext 3 inverted bottleneck 4 large kernel size and 5 various layerwises.In this part of the series we will be looking at the performance of a resnet based on a multistage architectures.In this section we investigate the architectural differences between vision and convnet architectures on a macro scales.In the first part of our series on resnet50200 we explore the use of convnext as a compute regime for resnet50200 we begin by exploring the use of convnext as a compute regime for resnet50200 we begin by exploring the use of convnext as a compute regimes.Table 1 classication accuracys.Key words maskrcnn cascade maskrcnn cascade maskrcnn 3 schedule cascade maskrcnn 3 schedule cascade maskrcnn 3 schedule cascade maskrcnn 3 schedule cascade maskrcnn 3 schedule cascade maskrcnn 3 schedule cascade maskrcnn 3 schedule cascades.Convnexts a pure convnet model that can compete with stateoftheart hierarchical vision transformers across multiple computer vision benchmarkss.All results are copyrighteds.Table 9 detailed architecture specications for resnet50 convnextt and swint model in1k acc gflopss.A new class of image recognition convnexts has been proposed and we present a preliminary study showing promising signals that convnext employed with standard convnet modules and simple in design could be practically efcients.10 kai chen jiaqi wang jiangmiao pang yuhang cao yuxiong oxiao li shuyang sun wansenwei zi liu liu jiarui xu zheng zhang dazhi cheng chephathon shlens quoc v les.The following papers have been published in the journal of the chinese academy of engineerings.Researchers from the massachusetts institute of technology mit and the chinese academy of sciences cas have been working together to develop new ways of understanding sceness.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
